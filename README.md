# Retrieval-Augmented-Generation-with-Llama-2
About Retrieval-Augmented Generation (RAG) with Llama 2 and LangChain to perform generative question answering (QA)

Retrieval-Augmented Generation (RAG) is a technique that combines a retriever and a generative language model to deliver accurate response. It involves retrieving relevant information from a large corpus and then generating contextually appropriate responses to queries. Here we use the quantized version of the Llama 2 13B LLM with LangChain to perform generative QA with RAG. The notebook file has been tested in Google Colab with T4 GPU. 

![image](https://github.com/ZoreAnuj/Retrieval-Augmented-Generation-with-Llama-2/assets/95142805/3d9fdf58-4fe7-4fca-a366-890abc35f146)


Figure: A schematic representation of RAG with a retriever and an LLM
